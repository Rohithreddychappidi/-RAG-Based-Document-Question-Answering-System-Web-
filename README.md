# -RAG-Based-Document-Question-Answering-System-Web-
This project is a lightweight Retrieval-Augmented Generation (RAG) pipeline built with **Python**, **Flask**, **FAISS**, **LLM (OpenAI/Ollama)**, and **Docker**. Upload a PDF and ask questions â€” the app fetches relevant document chunks and answers using an LLM.
# ğŸ§  RAG-Based Document Question Answering System

This project is a lightweight Retrieval-Augmented Generation (RAG) pipeline built with **Python**, **Flask**, **FAISS**, **LLM (OpenAI/Ollama)**, and **Docker**. Upload a PDF and ask questions â€” the app fetches relevant document chunks and answers using an LLM.

---

## ğŸš€ Features

- ğŸ“„ Upload a PDF and process it into chunks
- ğŸ§  Uses FAISS vector store for fast semantic search
- ğŸ” Embeds using OpenAI or local `ollama.embeddings`
- ğŸ¤– Answers questions using a Language Model (LLM)
- ğŸ³ Easily deployable using Docker

---

## ğŸ§° Tech Stack

| Layer           | Tool / Library           |
|----------------|--------------------------|
| Frontend       | HTML + JavaScript (Flask template) |
| Backend        | Flask (Python)            |
| Embeddings     | OpenAI / Ollama           |
| Vector Store   | FAISS                     |
| LLM            | OpenAI Chat / LLaMA via Ollama |
| Deployment     | Docker                    |

---

## ğŸ› ï¸ Installation

### 1. Clone the repo

```bash
git clone https://github.com/your-username/rag_app.git
cd rag_app

#2. Set up Python environment

python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

python app.py


ğŸ³ Docker Deployment
1. Build Docker Image

docker build -t rag_app .

2. Run Container

docker run -p 5000:5000 rag_app

ğŸ“ Project Structure
csharp
Copy
Edit
rag_app/
â”œâ”€â”€ app.py                # Flask backend
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        # Upload + Chat UI
â”œâ”€â”€ static/
â”‚   â””â”€â”€ styles.css        # Optional styles
â”œâ”€â”€ rag_pipeline.py       # Core RAG logic (loading, embedding, retrieval)
â”œâ”€â”€ Dockerfile            # For Docker container
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project overview

âœï¸ Example Use
Upload a PDF file
Ask: "What is the main topic of the document?"
LLM replies using the most relevant context from the uploaded document

----
ğŸ“¦ Requirements
Python 3.9+
Docker (optional, for containerization)
FAISS
Flask
LangChain
OpenAI / Ollama
---
